{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saharnaz Babaei Balderlou \n",
    "# Problem Set 3\n",
    "#------------------------------------------------------------------------------\n",
    "# Import required packages\n",
    "#------------------------------------------------------------------------------\n",
    "import pandas as pd # will be used to read .dta file by .read_stata()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # will be used to see the obvious relationship of desired variables in a scatterplot\n",
    "#%matplotlib inline\n",
    "import math # to use in some equations\n",
    "from scipy.optimize import minimize # for optimization of Likelihood function (MLE method)\n",
    "import scipy.optimize as opt\n",
    "import statsmodels.api as statmod \n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Read data and prepare to utilize (Part 1 & 2)\n",
    "#------------------------------------------------------------------------------\n",
    "df1 = pd.read_stata('PS3_data.dta') \n",
    "# My note for later: https://www.shanelynn.ie/using-pandas-dataframe-creating-editing-viewing-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id68</th>\n",
       "      <th>year</th>\n",
       "      <th>intid</th>\n",
       "      <th>relhh</th>\n",
       "      <th>hannhrs</th>\n",
       "      <th>wannhrs</th>\n",
       "      <th>hlabinc</th>\n",
       "      <th>wlabinc</th>\n",
       "      <th>nochild</th>\n",
       "      <th>wrace</th>\n",
       "      <th>...</th>\n",
       "      <th>redpregovinc</th>\n",
       "      <th>hsex</th>\n",
       "      <th>wsex</th>\n",
       "      <th>age</th>\n",
       "      <th>wage</th>\n",
       "      <th>hpersno</th>\n",
       "      <th>wpersno</th>\n",
       "      <th>hyrsed</th>\n",
       "      <th>wyrsed</th>\n",
       "      <th>pce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>1</td>\n",
       "      <td>Head</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>2</td>\n",
       "      <td>Head</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1967</td>\n",
       "      <td>3</td>\n",
       "      <td>Head</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1967</td>\n",
       "      <td>4</td>\n",
       "      <td>Head</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1967</td>\n",
       "      <td>5</td>\n",
       "      <td>Head</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id68  year  intid relhh  hannhrs  wannhrs  hlabinc  wlabinc  nochild  \\\n",
       "0     1  1967      1  Head   1200.0   2000.0      NaN      NaN        0   \n",
       "1     2  1967      2  Head      0.0      0.0      NaN      NaN        0   \n",
       "2     3  1967      3  Head      0.0      0.0      NaN      NaN        0   \n",
       "3     4  1967      4  Head   1560.0      0.0      NaN      NaN        6   \n",
       "4     5  1967      5  Head   2500.0   2000.0      NaN      NaN        3   \n",
       "\n",
       "   wrace  ...  redpregovinc  hsex  wsex   age  wage  hpersno  wpersno  hyrsed  \\\n",
       "0    NaN  ...        5614.0   1.0   2.0  52.0  46.0      1.0      2.0     8.0   \n",
       "1    NaN  ...           0.0   1.0   2.0  56.0  57.0      1.0      2.0     3.0   \n",
       "2    NaN  ...           0.0   1.0   2.0  77.0  64.0      1.0      2.0     NaN   \n",
       "3    1.0  ...        3280.0   1.0   2.0  45.0  44.0      1.0      2.0     8.0   \n",
       "4    1.0  ...        7900.0   1.0   2.0  24.0  22.0      1.0      2.0    10.0   \n",
       "\n",
       "   wyrsed  pce  \n",
       "0     8.0  0.0  \n",
       "1     3.0  0.0  \n",
       "2     3.0  0.0  \n",
       "3     5.0  0.0  \n",
       "4     9.0  0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataframe: \")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id68</th>\n",
       "      <th>year</th>\n",
       "      <th>intid</th>\n",
       "      <th>hannhrs</th>\n",
       "      <th>wannhrs</th>\n",
       "      <th>hlabinc</th>\n",
       "      <th>wlabinc</th>\n",
       "      <th>nochild</th>\n",
       "      <th>wrace</th>\n",
       "      <th>hrace</th>\n",
       "      <th>...</th>\n",
       "      <th>redpregovinc</th>\n",
       "      <th>hsex</th>\n",
       "      <th>wsex</th>\n",
       "      <th>age</th>\n",
       "      <th>wage</th>\n",
       "      <th>hpersno</th>\n",
       "      <th>wpersno</th>\n",
       "      <th>hyrsed</th>\n",
       "      <th>wyrsed</th>\n",
       "      <th>pce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>123786.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>9.023300e+04</td>\n",
       "      <td>48496.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>90603.000000</td>\n",
       "      <td>123656.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.237860e+05</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>80758.0</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>80758.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "      <td>80758.000000</td>\n",
       "      <td>122809.000000</td>\n",
       "      <td>80091.000000</td>\n",
       "      <td>123786.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1494.639475</td>\n",
       "      <td>1984.831273</td>\n",
       "      <td>3271.379429</td>\n",
       "      <td>1679.269897</td>\n",
       "      <td>633.026917</td>\n",
       "      <td>4.211505e+04</td>\n",
       "      <td>22026.289062</td>\n",
       "      <td>0.843771</td>\n",
       "      <td>1.098220</td>\n",
       "      <td>1.129731</td>\n",
       "      <td>...</td>\n",
       "      <td>3.012258e+04</td>\n",
       "      <td>1.233072</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.545547</td>\n",
       "      <td>41.390785</td>\n",
       "      <td>39.620201</td>\n",
       "      <td>55.346169</td>\n",
       "      <td>12.666091</td>\n",
       "      <td>12.720081</td>\n",
       "      <td>0.557690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>838.901790</td>\n",
       "      <td>9.836212</td>\n",
       "      <td>2277.056058</td>\n",
       "      <td>1061.704712</td>\n",
       "      <td>878.422791</td>\n",
       "      <td>4.670424e+04</td>\n",
       "      <td>21336.107422</td>\n",
       "      <td>1.182829</td>\n",
       "      <td>0.356161</td>\n",
       "      <td>0.394627</td>\n",
       "      <td>...</td>\n",
       "      <td>4.588795e+04</td>\n",
       "      <td>0.422940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.623671</td>\n",
       "      <td>14.786721</td>\n",
       "      <td>69.003265</td>\n",
       "      <td>77.864296</td>\n",
       "      <td>2.917721</td>\n",
       "      <td>2.422607</td>\n",
       "      <td>0.265198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.353981e-01</td>\n",
       "      <td>1.192780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.324040e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.979858e+04</td>\n",
       "      <td>8016.247070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.362158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>2984.000000</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.460022e+04</td>\n",
       "      <td>18122.412109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.599887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2224.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>4763.000000</td>\n",
       "      <td>2350.000000</td>\n",
       "      <td>1454.000000</td>\n",
       "      <td>5.267309e+04</td>\n",
       "      <td>30256.060547</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.910775e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.786908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>16968.000000</td>\n",
       "      <td>7800.000000</td>\n",
       "      <td>5840.000000</td>\n",
       "      <td>3.771521e+06</td>\n",
       "      <td>856942.062500</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660000e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.928007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id68           year          intid        hannhrs  \\\n",
       "count  123786.000000  123786.000000  123786.000000  123786.000000   \n",
       "mean     1494.639475    1984.831273    3271.379429    1679.269897   \n",
       "std       838.901790       9.836212    2277.056058    1061.704712   \n",
       "min         1.000000    1967.000000       1.000000       0.000000   \n",
       "25%       772.000000    1977.000000    1444.000000     832.000000   \n",
       "50%      1517.000000    1985.000000    2984.000000    1976.000000   \n",
       "75%      2224.000000    1993.000000    4763.000000    2350.000000   \n",
       "max      2930.000000    2002.000000   16968.000000    7800.000000   \n",
       "\n",
       "             wannhrs       hlabinc        wlabinc        nochild  \\\n",
       "count  123786.000000  9.023300e+04   48496.000000  123786.000000   \n",
       "mean      633.026917  4.211505e+04   22026.289062       0.843771   \n",
       "std       878.422791  4.670424e+04   21336.107422       1.182829   \n",
       "min         0.000000  6.353981e-01       1.192780       0.000000   \n",
       "25%         0.000000  1.979858e+04    8016.247070       0.000000   \n",
       "50%         0.000000  3.460022e+04   18122.412109       0.000000   \n",
       "75%      1454.000000  5.267309e+04   30256.060547       2.000000   \n",
       "max      5840.000000  3.771521e+06  856942.062500      11.000000   \n",
       "\n",
       "              wrace          hrace  ...  redpregovinc           hsex     wsex  \\\n",
       "count  90603.000000  123656.000000  ...  1.237860e+05  123786.000000  80758.0   \n",
       "mean       1.098220       1.129731  ...  3.012258e+04       1.233072      2.0   \n",
       "std        0.356161       0.394627  ...  4.588795e+04       0.422940      0.0   \n",
       "min        1.000000       1.000000  ... -1.324040e+05       1.000000      2.0   \n",
       "25%        1.000000       1.000000  ...  7.700000e+03       1.000000      2.0   \n",
       "50%        1.000000       1.000000  ...  1.900000e+04       1.000000      2.0   \n",
       "75%        1.000000       1.000000  ...  3.910775e+04       1.000000      2.0   \n",
       "max        8.000000       8.000000  ...  3.660000e+06       2.000000      2.0   \n",
       "\n",
       "                 age          wage        hpersno       wpersno  \\\n",
       "count  123786.000000  80758.000000  123786.000000  80758.000000   \n",
       "mean       45.545547     41.390785      39.620201     55.346169   \n",
       "std        17.623671     14.786721      69.003265     77.864296   \n",
       "min        16.000000     13.000000       1.000000      1.000000   \n",
       "25%        31.000000     29.000000       1.000000      2.000000   \n",
       "50%        42.000000     39.000000       3.000000      3.000000   \n",
       "75%        58.000000     51.000000      22.000000    170.000000   \n",
       "max       102.000000     95.000000     227.000000    231.000000   \n",
       "\n",
       "              hyrsed        wyrsed            pce  \n",
       "count  122809.000000  80091.000000  123786.000000  \n",
       "mean       12.666091     12.720081       0.557690  \n",
       "std         2.917721      2.422607       0.265198  \n",
       "min         1.000000      1.000000       0.000000  \n",
       "25%        12.000000     12.000000       0.362158  \n",
       "50%        12.000000     12.000000       0.599887  \n",
       "75%        15.000000     14.000000       0.786908  \n",
       "max        17.000000     17.000000       0.928007  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hlabinc = annual labor income of the head\n",
    "hannhrs = annual hours of the head\n",
    "hsex = gender of the head (1 = Male, 2 = Female)\n",
    "hrace = race of the head (1 = white, 2 = Black, 3 = Native American, 4 = Asian/Pacific Islander, 5 = Hispanic, 6,7 = Other)\n",
    "age = age of the head\n",
    "hyrsed = years of education of the head\n",
    "'''\n",
    "print(\"Data Statistics:\")\n",
    "df1.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatterplot between annual labor inome of the head and years of education of the head\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x396 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Scatterplot between annual labor inome of the head and years of education of the head\")\n",
    "plt.style.use('seaborn')\n",
    "df1.plot(x = 'hyrsed', y = 'hlabinc', kind = 'scatter')\n",
    "plt.show()\n",
    "plt.savefig('scat_inc_edu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id68</th>\n",
       "      <th>year</th>\n",
       "      <th>intid</th>\n",
       "      <th>hannhrs</th>\n",
       "      <th>wannhrs</th>\n",
       "      <th>hlabinc</th>\n",
       "      <th>wlabinc</th>\n",
       "      <th>nochild</th>\n",
       "      <th>wrace</th>\n",
       "      <th>hrace</th>\n",
       "      <th>...</th>\n",
       "      <th>redpregovinc</th>\n",
       "      <th>hsex</th>\n",
       "      <th>wsex</th>\n",
       "      <th>age</th>\n",
       "      <th>wage</th>\n",
       "      <th>hpersno</th>\n",
       "      <th>wpersno</th>\n",
       "      <th>hyrsed</th>\n",
       "      <th>wyrsed</th>\n",
       "      <th>pce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89688.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>8.968800e+04</td>\n",
       "      <td>45338.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>73835.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.968800e+04</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>62705.0</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>62705.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>62705.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "      <td>62244.000000</td>\n",
       "      <td>89688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1510.782992</td>\n",
       "      <td>1986.315338</td>\n",
       "      <td>3515.175007</td>\n",
       "      <td>2067.510254</td>\n",
       "      <td>763.457153</td>\n",
       "      <td>4.211382e+04</td>\n",
       "      <td>21914.417969</td>\n",
       "      <td>0.949737</td>\n",
       "      <td>1.096932</td>\n",
       "      <td>1.123695</td>\n",
       "      <td>...</td>\n",
       "      <td>3.774112e+04</td>\n",
       "      <td>1.179935</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.012321</td>\n",
       "      <td>38.289116</td>\n",
       "      <td>48.742619</td>\n",
       "      <td>65.553192</td>\n",
       "      <td>13.228726</td>\n",
       "      <td>13.029015</td>\n",
       "      <td>0.609756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>834.667982</td>\n",
       "      <td>8.791094</td>\n",
       "      <td>2314.034043</td>\n",
       "      <td>756.294312</td>\n",
       "      <td>913.115479</td>\n",
       "      <td>4.675834e+04</td>\n",
       "      <td>20676.205078</td>\n",
       "      <td>1.168268</td>\n",
       "      <td>0.354777</td>\n",
       "      <td>0.390376</td>\n",
       "      <td>...</td>\n",
       "      <td>4.853038e+04</td>\n",
       "      <td>0.384065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.287443</td>\n",
       "      <td>12.255554</td>\n",
       "      <td>73.709778</td>\n",
       "      <td>81.090965</td>\n",
       "      <td>2.526992</td>\n",
       "      <td>2.225578</td>\n",
       "      <td>0.208654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1971.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.353981e-01</td>\n",
       "      <td>1.192780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.359900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>783.000000</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>1673.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.976367e+04</td>\n",
       "      <td>8042.066406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.400000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.421747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1542.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>3321.000000</td>\n",
       "      <td>2064.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>3.460022e+04</td>\n",
       "      <td>18120.386719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.640000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.614522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2240.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>5058.000000</td>\n",
       "      <td>2453.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>5.267309e+04</td>\n",
       "      <td>30172.169922</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.744325e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.786908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>16968.000000</td>\n",
       "      <td>7800.000000</td>\n",
       "      <td>5840.000000</td>\n",
       "      <td>3.771521e+06</td>\n",
       "      <td>685266.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660000e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.928007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id68          year         intid       hannhrs       wannhrs  \\\n",
       "count  89688.000000  89688.000000  89688.000000  89688.000000  89688.000000   \n",
       "mean    1510.782992   1986.315338   3515.175007   2067.510254    763.457153   \n",
       "std      834.667982      8.791094   2314.034043    756.294312    913.115479   \n",
       "min        1.000000   1971.000000      1.000000      0.000000      0.000000   \n",
       "25%      783.000000   1979.000000   1673.000000   1800.000000      0.000000   \n",
       "50%     1542.000000   1986.000000   3321.000000   2064.000000     74.000000   \n",
       "75%     2240.000000   1993.000000   5058.000000   2453.000000   1700.000000   \n",
       "max     2930.000000   2002.000000  16968.000000   7800.000000   5840.000000   \n",
       "\n",
       "            hlabinc        wlabinc       nochild         wrace         hrace  \\\n",
       "count  8.968800e+04   45338.000000  89688.000000  73835.000000  89688.000000   \n",
       "mean   4.211382e+04   21914.417969      0.949737      1.096932      1.123695   \n",
       "std    4.675834e+04   20676.205078      1.168268      0.354777      0.390376   \n",
       "min    6.353981e-01       1.192780      0.000000      1.000000      1.000000   \n",
       "25%    1.976367e+04    8042.066406      0.000000      1.000000      1.000000   \n",
       "50%    3.460022e+04   18120.386719      0.000000      1.000000      1.000000   \n",
       "75%    5.267309e+04   30172.169922      2.000000      1.000000      1.000000   \n",
       "max    3.771521e+06  685266.750000     11.000000      8.000000      3.000000   \n",
       "\n",
       "       ...  redpregovinc          hsex     wsex           age          wage  \\\n",
       "count  ...  8.968800e+04  89688.000000  62705.0  89688.000000  62705.000000   \n",
       "mean   ...  3.774112e+04      1.179935      2.0     40.012321     38.289116   \n",
       "std    ...  4.853038e+04      0.384065      0.0     13.287443     12.255554   \n",
       "min    ... -9.359900e+04      1.000000      2.0     17.000000     14.000000   \n",
       "25%    ...  1.400000e+04      1.000000      2.0     29.000000     29.000000   \n",
       "50%    ...  2.640000e+04      1.000000      2.0     38.000000     36.000000   \n",
       "75%    ...  4.744325e+04      1.000000      2.0     49.000000     46.000000   \n",
       "max    ...  3.660000e+06      2.000000      2.0     95.000000     93.000000   \n",
       "\n",
       "            hpersno       wpersno        hyrsed        wyrsed           pce  \n",
       "count  89688.000000  62705.000000  89688.000000  62244.000000  89688.000000  \n",
       "mean      48.742619     65.553192     13.228726     13.029015      0.609756  \n",
       "std       73.709778     81.090965      2.526992      2.225578      0.208654  \n",
       "min        1.000000      1.000000      1.000000      1.000000      0.247121  \n",
       "25%        1.000000      2.000000     12.000000     12.000000      0.421747  \n",
       "50%        4.000000      4.000000     12.000000     12.000000      0.614522  \n",
       "75%      170.000000    170.000000     16.000000     15.000000      0.786908  \n",
       "max      227.000000    231.000000     17.000000     17.000000      0.928007  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df1_subset = df1.dropna(how = 'any', subset = ['hlabinc', 'hannhrs', 'hsex', 'hrace', 'age', 'hyrsed'])\n",
    "df1_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id68</th>\n",
       "      <th>year</th>\n",
       "      <th>intid</th>\n",
       "      <th>hlabinc</th>\n",
       "      <th>hannhrs</th>\n",
       "      <th>hsex</th>\n",
       "      <th>hrace</th>\n",
       "      <th>age</th>\n",
       "      <th>hyrsed</th>\n",
       "      <th>annhrs</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>ln_hrwage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>5.706200e+04</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.0</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "      <td>57062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1507.470558</td>\n",
       "      <td>1986.575672</td>\n",
       "      <td>3480.375311</td>\n",
       "      <td>5.282805e+04</td>\n",
       "      <td>2228.557617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.101416</td>\n",
       "      <td>39.243629</td>\n",
       "      <td>13.529967</td>\n",
       "      <td>2228.557617</td>\n",
       "      <td>24.320921</td>\n",
       "      <td>3.010804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>828.361439</td>\n",
       "      <td>8.712311</td>\n",
       "      <td>2253.229068</td>\n",
       "      <td>5.236477e+04</td>\n",
       "      <td>620.054077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369015</td>\n",
       "      <td>9.578858</td>\n",
       "      <td>2.450013</td>\n",
       "      <td>620.054077</td>\n",
       "      <td>25.209909</td>\n",
       "      <td>0.544096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1971.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666980e+01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000252</td>\n",
       "      <td>1.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>782.000000</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>1690.000000</td>\n",
       "      <td>3.037345e+04</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>13.950662</td>\n",
       "      <td>2.635527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1542.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>3296.000000</td>\n",
       "      <td>4.382858e+04</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>19.914677</td>\n",
       "      <td>2.991457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2225.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>5002.000000</td>\n",
       "      <td>6.138495e+04</td>\n",
       "      <td>2519.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2519.000000</td>\n",
       "      <td>27.790929</td>\n",
       "      <td>3.324710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>16968.000000</td>\n",
       "      <td>3.771521e+06</td>\n",
       "      <td>5840.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>5840.000000</td>\n",
       "      <td>1717.330322</td>\n",
       "      <td>7.448526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id68          year         intid       hlabinc       hannhrs  \\\n",
       "count  57062.000000  57062.000000  57062.000000  5.706200e+04  57062.000000   \n",
       "mean    1507.470558   1986.575672   3480.375311  5.282805e+04   2228.557617   \n",
       "std      828.361439      8.712311   2253.229068  5.236477e+04    620.054077   \n",
       "min        1.000000   1971.000000      1.000000  1.666980e+01      2.000000   \n",
       "25%      782.000000   1979.000000   1690.000000  3.037345e+04   1952.000000   \n",
       "50%     1542.000000   1987.000000   3296.000000  4.382858e+04   2160.000000   \n",
       "75%     2225.000000   1994.000000   5002.000000  6.138495e+04   2519.000000   \n",
       "max     2930.000000   2002.000000  16968.000000  3.771521e+06   5840.000000   \n",
       "\n",
       "          hsex         hrace           age        hyrsed        annhrs  \\\n",
       "count  57062.0  57062.000000  57062.000000  57062.000000  57062.000000   \n",
       "mean       1.0      1.101416     39.243629     13.529967   2228.557617   \n",
       "std        0.0      0.369015      9.578858      2.450013    620.054077   \n",
       "min        1.0      1.000000     25.000000      1.000000      2.000000   \n",
       "25%        1.0      1.000000     31.000000     12.000000   1952.000000   \n",
       "50%        1.0      1.000000     38.000000     13.000000   2160.000000   \n",
       "75%        1.0      1.000000     47.000000     16.000000   2519.000000   \n",
       "max        1.0      3.000000     60.000000     17.000000   5840.000000   \n",
       "\n",
       "             hrwage     ln_hrwage  \n",
       "count  57062.000000  57062.000000  \n",
       "mean      24.320921      3.010804  \n",
       "std       25.209909      0.544096  \n",
       "min        7.000252      1.945946  \n",
       "25%       13.950662      2.635527  \n",
       "50%       19.914677      2.991457  \n",
       "75%       27.790929      3.324710  \n",
       "max     1717.330322      7.448526  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select male heads of HH whose age is between 25 & 60 (included!), and wage > $7/hr\n",
    "df2 = df1_subset[['id68', 'year', 'intid', 'hlabinc', 'hannhrs', 'hsex', 'hrace', 'age', 'hyrsed']]\n",
    "df2['annhrs'] = df2['hannhrs'].where(df2['hannhrs']>0)\n",
    "df2['hrwage'] = df2['hlabinc']/df2['annhrs'] # compute hourly wage\n",
    "df2 = df2[(df2.hsex == 1.0) & (df2.age >= 25) & (df2.age <= 60) & (df2.hrwage > 7)] #Part 1\n",
    "df2['ln_hrwage'] = np.log(df2['hrwage']) #log of wages\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id68</th>\n",
       "      <th>year</th>\n",
       "      <th>intid</th>\n",
       "      <th>hlabinc</th>\n",
       "      <th>hannhrs</th>\n",
       "      <th>hsex</th>\n",
       "      <th>hrace</th>\n",
       "      <th>age</th>\n",
       "      <th>hyrsed</th>\n",
       "      <th>annhrs</th>\n",
       "      <th>hrwage</th>\n",
       "      <th>ln_hrwage</th>\n",
       "      <th>constant</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11161</th>\n",
       "      <td>402</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>62928.707031</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>41.318916</td>\n",
       "      <td>3.721320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11164</th>\n",
       "      <td>461</td>\n",
       "      <td>1971</td>\n",
       "      <td>4</td>\n",
       "      <td>22660.970703</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>11.274115</td>\n",
       "      <td>2.422509</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11166</th>\n",
       "      <td>1126</td>\n",
       "      <td>1971</td>\n",
       "      <td>8</td>\n",
       "      <td>29337.865234</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>10.257995</td>\n",
       "      <td>2.328057</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11173</th>\n",
       "      <td>284</td>\n",
       "      <td>1971</td>\n",
       "      <td>20</td>\n",
       "      <td>76885.437500</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>32.035599</td>\n",
       "      <td>3.466848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>50</td>\n",
       "      <td>1971</td>\n",
       "      <td>29</td>\n",
       "      <td>31968.156250</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>10.103716</td>\n",
       "      <td>2.312903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id68  year  intid       hlabinc  hannhrs  hsex  hrace   age  hyrsed  \\\n",
       "11161   402  1971      1  62928.707031   1523.0   1.0    1.0  51.0    12.0   \n",
       "11164   461  1971      4  22660.970703   2010.0   1.0    1.0  55.0     5.0   \n",
       "11166  1126  1971      8  29337.865234   2860.0   1.0    1.0  25.0    16.0   \n",
       "11173   284  1971     20  76885.437500   2400.0   1.0    1.0  39.0    16.0   \n",
       "11175    50  1971     29  31968.156250   3164.0   1.0    1.0  36.0    12.0   \n",
       "\n",
       "       annhrs     hrwage  ln_hrwage  constant  White  Black  Others  \n",
       "11161  1523.0  41.318916   3.721320         1      1      0       0  \n",
       "11164  2010.0  11.274115   2.422509         1      1      0       0  \n",
       "11166  2860.0  10.257995   2.328057         1      1      0       0  \n",
       "11173  2400.0  32.035599   3.466848         1      1      0       0  \n",
       "11175  3164.0  10.103716   2.312903         1      1      0       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a note for me: https://stackoverflow.com/questions/11587782/creating-dummy-variables-in-pandas-for-python\n",
    "race_dummy = pd.get_dummies(df2['hrace']) # Defining race dummies (There is no Hispanic individual in dataset)\n",
    "df2['constant'] = 1\n",
    "data = pd.concat([df2, race_dummy], axis = 1) \n",
    "data.rename(columns = {1.0: 'White', 2.0: 'Black', 3.0: 'Others'}, inplace = True) #final data \"data\"; ready to estimate model \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id68           int16\n",
       "year           int16\n",
       "intid          int16\n",
       "hlabinc      float32\n",
       "hannhrs      float32\n",
       "hsex         float32\n",
       "hrace        float64\n",
       "age          float32\n",
       "hyrsed       float32\n",
       "annhrs       float32\n",
       "hrwage       float32\n",
       "ln_hrwage    float32\n",
       "constant       int64\n",
       "White          uint8\n",
       "Black          uint8\n",
       "Others         uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data\", data)\n",
    "\n",
    "# Separate years for estimation\n",
    "data1971 = data[data['year'] == 1971]\n",
    "np.save(\"data1971\", data1971)\n",
    "data1980 = data[data['year'] == 1980]\n",
    "np.save(\"data1980\", data1980)\n",
    "data1990 = data[data['year'] == 1990]\n",
    "np.save(\"data1990\", data1990)\n",
    "data2000 = data[data['year'] == 2000]\n",
    "np.save(\"data2000\", data2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# ML estimation (Part 3)\n",
    "#------------------------------------------------------------------------------\n",
    "'''\n",
    "ln(w_it) = alpha + beta_1 * Educ_it + beta_2 * Age_it + beta_3 * Black_it + beta_4 * Hispanic_it + beta_5 * OtherRace_it + epsilon_it\n",
    "w_it = wage of individual i in survey year t\n",
    "Educ_it = education in years\n",
    "Age_it = age in years\n",
    "Black_it, Hispanic_it, OtherRace_it = dummy variables for race = Black, Hispanic, Not (belongs to {White, Black, Hispanic})\n",
    "'''\n",
    "\n",
    "# Define my objective function\n",
    "def myLL(params, t): \n",
    "    # Coeff.s\n",
    "    beta0, beta1, beta2, beta3, beta4, sigma = params\n",
    "    beta = np.array([beta0, beta1, beta2, beta3, beta4])\n",
    "    n = len(t)\n",
    "    # Independent variables matrix (No Hispanic)\n",
    "    x0 = np.array(t['constant']).astype('float')\n",
    "    x1 = np.array(t['hyrsed']).astype('float')\n",
    "    x2 = np.array(t['age']).astype('float')\n",
    "    x3 = np.array(t['Black']).astype('float')\n",
    "    x4 = np.array(t['Others']).astype('float')\n",
    "    X = np.column_stack((x0, x1, x2, x3, x4))\n",
    "    # Dependent variable matrix\n",
    "    y = np.array(t['ln_hrwage']).astype('float')\n",
    "    y_bar = np.dot(X, beta)\n",
    "    ll = (-(n/2)*np.log(2*np.pi) - (n/2)*np.log(sigma**2) - (1/(2*sigma**2))*((y-y_bar).T @ (y - y_bar)))\n",
    "    return (-ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE coefficients:  Total dataset\n",
      "=============================\n",
      " final_simplex: (array([[ 1.39309627,  0.0781139 ,  0.0145177 , -0.16239436,  0.01108259,\n",
      "         0.48968236],\n",
      "       [ 1.3930527 ,  0.0781193 ,  0.01451702, -0.1624352 ,  0.01106685,\n",
      "         0.4896769 ],\n",
      "       [ 1.39309914,  0.07811356,  0.01451801, -0.16244586,  0.0109965 ,\n",
      "         0.48968791],\n",
      "       [ 1.39307198,  0.07811841,  0.01451689, -0.16244504,  0.01111231,\n",
      "         0.48968793],\n",
      "       [ 1.39313048,  0.07811415,  0.01451716, -0.16247289,  0.01103884,\n",
      "         0.48967662],\n",
      "       [ 1.3930366 ,  0.07812007,  0.01451746, -0.16232213,  0.01103599,\n",
      "         0.48968893],\n",
      "       [ 1.39317897,  0.07811236,  0.01451641, -0.16240374,  0.01101757,\n",
      "         0.48968747]]), array([40225.31420626, 40225.31421319, 40225.31422174, 40225.31422664,\n",
      "       40225.31424347, 40225.3142488 , 40225.3142569 ]))\n",
      "           fun: 40225.31420626389\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1162\n",
      "           nit: 749\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 1.39309627,  0.0781139 ,  0.0145177 , -0.16239436,  0.01108259,\n",
      "        0.48968236])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1971\n",
      "=============================\n",
      " final_simplex: (array([[ 1.47367052,  0.06973573,  0.01578288, -0.2340242 , -0.42911197,\n",
      "         0.41157107],\n",
      "       [ 1.47361046,  0.06974115,  0.01578231, -0.23397205, -0.42911159,\n",
      "         0.4115673 ],\n",
      "       [ 1.47358856,  0.06973973,  0.01578298, -0.23403964, -0.42908831,\n",
      "         0.41157356],\n",
      "       [ 1.4736112 ,  0.06973677,  0.01578324, -0.23399855, -0.42909645,\n",
      "         0.41156275],\n",
      "       [ 1.47371123,  0.06973561,  0.01578128, -0.23405239, -0.42911123,\n",
      "         0.41156895],\n",
      "       [ 1.47367534,  0.06973616,  0.01578253, -0.23405703, -0.42909264,\n",
      "         0.41156107],\n",
      "       [ 1.47371518,  0.06973268,  0.01578194, -0.23400247, -0.42914202,\n",
      "         0.41158344]]), array([752.78870883, 752.78870947, 752.78871087, 752.78871124,\n",
      "       752.78871183, 752.7887139 , 752.78871442]))\n",
      "           fun: 752.7887088280063\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 786\n",
      "           nit: 496\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 1.47367052,  0.06973573,  0.01578288, -0.2340242 , -0.42911197,\n",
      "        0.41157107])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1980\n",
      "=============================\n",
      " final_simplex: (array([[ 1.6132899 ,  0.0675381 ,  0.01269899, -0.10263128,  0.0136228 ,\n",
      "         0.44926559],\n",
      "       [ 1.61305248,  0.06756315,  0.01269762, -0.10267639,  0.01366701,\n",
      "         0.44928481],\n",
      "       [ 1.61340895,  0.06753724,  0.01269743, -0.10258163,  0.01316331,\n",
      "         0.4492538 ],\n",
      "       [ 1.61323268,  0.06753902,  0.01269958, -0.10288796,  0.01379478,\n",
      "         0.44921281],\n",
      "       [ 1.61374566,  0.06752382,  0.01269221, -0.10279164,  0.01359016,\n",
      "         0.44925456],\n",
      "       [ 1.61356332,  0.06752716,  0.01269722, -0.10289006,  0.01380762,\n",
      "         0.44925926],\n",
      "       [ 1.61340448,  0.06753553,  0.01269851, -0.10301816,  0.01315615,\n",
      "         0.4492721 ]]), array([1148.39323838, 1148.39324439, 1148.39325561, 1148.39325705,\n",
      "       1148.39326198, 1148.39326495, 1148.39326782]))\n",
      "           fun: 1148.39323837555\n",
      "       message: 'Maximum number of function evaluations has been exceeded.'\n",
      "          nfev: 1201\n",
      "           nit: 774\n",
      "        status: 1\n",
      "       success: False\n",
      "             x: array([ 1.6132899 ,  0.0675381 ,  0.01269899, -0.10263128,  0.0136228 ,\n",
      "        0.44926559])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1990\n",
      "=============================\n",
      " final_simplex: (array([[ 0.66841963,  0.11863582,  0.01749401, -0.14739724, -0.65477016,\n",
      "         0.4893061 ],\n",
      "       [ 0.66835602,  0.11864754,  0.0174916 , -0.14732871, -0.65471547,\n",
      "         0.4893005 ],\n",
      "       [ 0.66851798,  0.1186424 ,  0.01748935, -0.14746815, -0.65485297,\n",
      "         0.48929941],\n",
      "       [ 0.66837051,  0.11864686,  0.01749027, -0.14739821, -0.65472676,\n",
      "         0.48930142],\n",
      "       [ 0.66838604,  0.11864412,  0.01749209, -0.14745596, -0.65473298,\n",
      "         0.48929077],\n",
      "       [ 0.66840779,  0.11864285,  0.01749167, -0.14741798, -0.65476171,\n",
      "         0.4893055 ],\n",
      "       [ 0.66846521,  0.11864223,  0.01749013, -0.14735539, -0.65480545,\n",
      "         0.48929722]]), array([1430.23330055, 1430.23330579, 1430.23330615, 1430.23330668,\n",
      "       1430.23330737, 1430.23330866, 1430.23331002]))\n",
      "           fun: 1430.233300554175\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 852\n",
      "           nit: 547\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 0.66841963,  0.11863582,  0.01749401, -0.14739724, -0.65477016,\n",
      "        0.4893061 ])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 2000\n",
      "=============================\n",
      " final_simplex: (array([[ 1.16169112,  0.10915564,  0.01099325, -0.24608949, -0.06074079,\n",
      "         0.5395586 ],\n",
      "       [ 1.16172663,  0.10915285,  0.01099324, -0.24602461, -0.06069615,\n",
      "         0.53956308],\n",
      "       [ 1.16176407,  0.10914997,  0.01099332, -0.2460459 , -0.06071587,\n",
      "         0.53956483],\n",
      "       [ 1.16165857,  0.10915336,  0.01099491, -0.24603163, -0.06075654,\n",
      "         0.53955864],\n",
      "       [ 1.16175584,  0.10915004,  0.01099372, -0.24609096, -0.06069359,\n",
      "         0.53956002],\n",
      "       [ 1.16161566,  0.10915489,  0.01099514, -0.24607217, -0.06067408,\n",
      "         0.53955494],\n",
      "       [ 1.1616349 ,  0.10915557,  0.01099461, -0.24605415, -0.06071328,\n",
      "         0.53954611]]), array([2068.985145  , 2068.98514519, 2068.98514543, 2068.98514579,\n",
      "       2068.98514608, 2068.98514614, 2068.98514625]))\n",
      "           fun: 2068.985144996586\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 1143\n",
      "           nit: 742\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 1.16169112,  0.10915564,  0.01099325, -0.24608949, -0.06074079,\n",
      "        0.5395586 ])\n",
      "_____________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nyears = [\"data1971.npy\", \"data1980.npy\", \"data1990.npy\", \"data2000.npy\", \"data.npy\"]\\nfor t in years:\\n    res_MLE = opt.minimize(myLL, params, args=(t), method=\\'Nelder-Mead\\', bounds=bounds)\\n    print(\"MLE coefficients: \", t)\\n    print(res_MLE)\\n    print(\"_____________________________________\")\\n#### I tried this loop so many times and attempted to troubleshoot but finally I got this error: \"string indices must be integers\"\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLE; 'Nelder-Mead'\n",
    "nbeta = 5\n",
    "beta = np.zeros(nbeta)\n",
    "beta0 = 0.1\n",
    "beta1 = 0.1\n",
    "beta2 = 0.1\n",
    "beta3 = 0.1\n",
    "beta4 = 0.1\n",
    "sigma = 0.1\n",
    "beta = [beta0, beta1, beta2, beta3, beta4]\n",
    "params = [beta0, beta1, beta2, beta3, beta4, sigma]\n",
    "\n",
    "bounds = ((1e-10, None), (None,None), (None,None), (None,None), (None,None), (None,None))\n",
    "\n",
    "res_NM = opt.minimize(myLL, params, args=(data), method='Nelder-Mead', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"Total dataset\")\n",
    "print(\"=============================\")\n",
    "print(res_NM)\n",
    "print(\"_____________________________________\")\n",
    "res71_NM = opt.minimize(myLL, params, args=(data1971), method='Nelder-Mead', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1971\")\n",
    "print(\"=============================\")\n",
    "print(res71_NM)\n",
    "print(\"_____________________________________\")\n",
    "res80_NM = opt.minimize(myLL, params, args=(data1980), method='Nelder-Mead', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1980\")\n",
    "print(\"=============================\")\n",
    "print(res80_NM)\n",
    "print(\"_____________________________________\")\n",
    "res90_NM = opt.minimize(myLL, params, args=(data1990), method='Nelder-Mead', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1990\")\n",
    "print(\"=============================\")\n",
    "print(res90_NM)\n",
    "print(\"_____________________________________\")\n",
    "res2000_NM = opt.minimize(myLL, params, args=(data2000), method='Nelder-Mead', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 2000\")\n",
    "print(\"=============================\")\n",
    "print(res2000_NM)\n",
    "print(\"_____________________________________\")\n",
    "'''\n",
    "years = [\"data1971.npy\", \"data1980.npy\", \"data1990.npy\", \"data2000.npy\", \"data.npy\"]\n",
    "for t in years:\n",
    "    res_MLE = opt.minimize(myLL, params, args=(t), method='Nelder-Mead', bounds=bounds)\n",
    "    print(\"MLE coefficients: \", t)\n",
    "    print(res_MLE)\n",
    "    print(\"_____________________________________\")\n",
    "#### I tried this loop so many times and attempted to troubleshoot but finally I got this error: \"string indices must be integers\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE coefficients:  Total dataset\n",
      "=============================\n",
      "      fun: 40225.31422021307\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 1.09284883, 11.08637662, 13.14037945,  0.50786184, -0.14697434,\n",
      "        2.48692231])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 469\n",
      "      nit: 57\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.39310199,  0.07811655,  0.01451693, -0.1623717 ,  0.0110262 ,\n",
      "        0.48968773])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1971\n",
      "=============================\n",
      "      fun: 728.0628698968592\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-5.36374500e-02, -4.52814675e-01, -2.12465920e+00,  3.09682946e-02,\n",
      "       -7.27595761e-04,  9.65997060e-02])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 602\n",
      "      nit: 76\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.55089935,  0.0668825 ,  0.01439164, -0.16381197,  0.0306993 ,\n",
      "        0.41010486])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1980\n",
      "=============================\n",
      "      fun: 1148.3932188882504\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-0.00618456, -0.013506  , -0.2509978 ,  0.01757599, -0.01077751,\n",
      "       -0.02992238])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 448\n",
      "      nit: 52\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.61306755,  0.06755729,  0.01269855, -0.10270202,  0.01346053,\n",
      "        0.44924099])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1990\n",
      "=============================\n",
      "      fun: 1393.8821505146818\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-1.40516931e-02, -2.04931894e-01, -5.94741323e-01,  5.91171556e-04,\n",
      "       -2.95585778e-04, -1.26192390e-02])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 511\n",
      "      nit: 64\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.11859519,  0.0975577 ,  0.01346543, -0.17202183, -0.05971275,\n",
      "        0.4835987 ])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 2000\n",
      "=============================\n",
      "      fun: 2068.985144417821\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.00245564,  0.03237801,  0.03697096, -0.00118234,  0.00172804,\n",
      "       -0.0125965 ])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 378\n",
      "      nit: 47\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 1.16170054,  0.1091542 ,  0.01099335, -0.24604792, -0.06072719,\n",
      "        0.53955657])\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLE; 'L-BFGS-B'\n",
    "nbeta = 5\n",
    "beta = np.zeros(nbeta)\n",
    "beta0 = 0.1\n",
    "beta1 = 0.1\n",
    "beta2 = 0.1\n",
    "beta3 = 0.1\n",
    "beta4 = 0.1\n",
    "sigma = 0.1\n",
    "beta = [beta0, beta1, beta2, beta3, beta4]\n",
    "params = [beta0, beta1, beta2, beta3, beta4, sigma]\n",
    "\n",
    "bounds = ((1e-10, None), (None,None), (None,None), (None,None), (None,None), (None,None))\n",
    "\n",
    "res_B = opt.minimize(myLL, params, args=(data), method='L-BFGS-B', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"Total dataset\")\n",
    "print(\"=============================\")\n",
    "print(res_B)\n",
    "print(\"_____________________________________\")\n",
    "res71_B = opt.minimize(myLL, params, args=(data1971), method='L-BFGS-B', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1971\")\n",
    "print(\"=============================\")\n",
    "print(res71_B)\n",
    "print(\"_____________________________________\")\n",
    "res80_B = opt.minimize(myLL, params, args=(data1980), method='L-BFGS-B', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1980\")\n",
    "print(\"=============================\")\n",
    "print(res80_B)\n",
    "print(\"_____________________________________\")\n",
    "res90_B = opt.minimize(myLL, params, args=(data1990), method='L-BFGS-B', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1990\")\n",
    "print(\"=============================\")\n",
    "print(res90_B)\n",
    "print(\"_____________________________________\")\n",
    "res2000_B = opt.minimize(myLL, params, args=(data2000), method='L-BFGS-B', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 2000\")\n",
    "print(\"=============================\")\n",
    "print(res2000_B)\n",
    "print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE coefficients:  Total dataset\n",
      "=============================\n",
      "     fun: 856650.0116380348\n",
      "     jac: array([ 0.       , -0.015625 , -0.0625   ,  0.       ,  0.       ,\n",
      "        0.0390625])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 158\n",
      "     nit: 17\n",
      "    njev: 17\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 1.35743523e+04,  4.71150427e+03, -3.11350044e+03, -5.31892140e+02,\n",
      "       -2.59472257e+02,  1.31954255e+06])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1971\n",
      "=============================\n",
      "     fun: 15636.46427784363\n",
      "     jac: array([-0.00146484, -0.01965332, -0.06494141,  0.        ,  0.        ,\n",
      "        0.04150391])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 237\n",
      "     nit: 27\n",
      "    njev: 27\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 3.27120481e+02, -6.60502420e+01, -1.91283818e+01, -8.28452642e-01,\n",
      "       -2.05362453e+00,  3.32262081e+04])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1980\n",
      "=============================\n",
      "     fun: 21421.229172243915\n",
      "     jac: array([-0.00170898, -0.02368164, -0.07006836, -0.00024414,  0.        ,\n",
      "        0.04516602])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 254\n",
      "     nit: 29\n",
      "    njev: 29\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 4.13130533e+02, -7.23919183e+01, -2.71742048e+01, -3.68930897e+00,\n",
      "       -2.06463090e+00,  4.10232241e+04])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 1990\n",
      "=============================\n",
      "     fun: 23477.188266910558\n",
      "     jac: array([-0.00195312, -0.02563477, -0.06518555, -0.00024414, -0.00024414,\n",
      "        0.04321289])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 306\n",
      "     nit: 35\n",
      "    njev: 35\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 4.66443728e+02, -2.83297299e+02,  4.13717527e+01, -1.11400203e+01,\n",
      "       -7.73958223e+00,  4.63011972e+04])\n",
      "_____________________________________\n",
      "MLE coefficients:  year == 2000\n",
      "=============================\n",
      "     fun: 30976.40648290343\n",
      "     jac: array([-0.00146484, -0.02294922, -0.05932617,  0.        ,  0.        ,\n",
      "        0.03955078])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 343\n",
      "     nit: 39\n",
      "    njev: 39\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 5.66873300e+02, -5.81415038e+02,  1.19630994e+02, -3.96679737e+01,\n",
      "       -2.74838032e+01,  6.52748983e+04])\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "# MLE; 'SLSQP'\n",
    "nbeta = 5\n",
    "beta = np.zeros(nbeta)\n",
    "beta0 = 0.1\n",
    "beta1 = 0.1\n",
    "beta2 = 0.1\n",
    "beta3 = 0.1\n",
    "beta4 = 0.1\n",
    "sigma = 0.1\n",
    "beta = [beta0, beta1, beta2, beta3, beta4]\n",
    "params = [beta0, beta1, beta2, beta3, beta4, sigma]\n",
    "\n",
    "bounds = ((1e-10, None), (None,None), (None,None), (None,None), (None,None), (None,None))\n",
    "\n",
    "res_S = opt.minimize(myLL, params, args=(data), method='SLSQP', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"Total dataset\")\n",
    "print(\"=============================\")\n",
    "print(res_S)\n",
    "print(\"_____________________________________\")\n",
    "res71_S = opt.minimize(myLL, params, args=(data1971), method='SLSQP', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1971\")\n",
    "print(\"=============================\")\n",
    "print(res71_S)\n",
    "print(\"_____________________________________\")\n",
    "res80_S = opt.minimize(myLL, params, args=(data1980), method='SLSQP', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1980\")\n",
    "print(\"=============================\")\n",
    "print(res80_S)\n",
    "print(\"_____________________________________\")\n",
    "res90_S = opt.minimize(myLL, params, args=(data1990), method='SLSQP', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 1990\")\n",
    "print(\"=============================\")\n",
    "print(res90_S)\n",
    "print(\"_____________________________________\")\n",
    "res2000_S = opt.minimize(myLL, params, args=(data2000), method='SLSQP', bounds=bounds)\n",
    "print(\"MLE coefficients: \", \"year == 2000\")\n",
    "print(\"=============================\")\n",
    "print(res2000_S)\n",
    "print(\"_____________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS; Full Sample\n",
      "===================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              ln_hrwage   R-squared:                       0.190\n",
      "Model:                            OLS   Adj. R-squared:                  0.190\n",
      "Method:                 Least Squares   F-statistic:                     3346.\n",
      "Date:                Sat, 28 Sep 2019   Prob (F-statistic):               0.00\n",
      "Time:                        16:57:50   Log-Likelihood:                -40225.\n",
      "No. Observations:               57062   AIC:                         8.046e+04\n",
      "Df Residuals:                   57057   BIC:                         8.051e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "constant       1.3930      0.015     94.165      0.000       1.364       1.422\n",
      "hyrsed         0.0781      0.001     92.558      0.000       0.076       0.080\n",
      "age            0.0145      0.000     67.707      0.000       0.014       0.015\n",
      "Black         -0.1624      0.009    -18.129      0.000      -0.180      -0.145\n",
      "Others         0.0111      0.014      0.800      0.424      -0.016       0.038\n",
      "==============================================================================\n",
      "Omnibus:                     5824.662   Durbin-Watson:                   1.937\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16025.805\n",
      "Skew:                           0.572   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.330   Cond. No.                         310.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OLS; year == 1971\n",
      "===================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              ln_hrwage   R-squared:                       0.244\n",
      "Model:                            OLS   Adj. R-squared:                  0.241\n",
      "Method:                 Least Squares   F-statistic:                     110.7\n",
      "Date:                Sat, 28 Sep 2019   Prob (F-statistic):           7.42e-82\n",
      "Time:                        16:57:50   Log-Likelihood:                -728.06\n",
      "No. Observations:                1380   AIC:                             1466.\n",
      "Df Residuals:                    1375   BIC:                             1492.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "constant       1.5510      0.073     21.382      0.000       1.409       1.693\n",
      "hyrsed         0.0669      0.004     17.814      0.000       0.060       0.074\n",
      "age            0.0144      0.001     12.902      0.000       0.012       0.017\n",
      "Black         -0.1639      0.045     -3.638      0.000      -0.252      -0.076\n",
      "Others         0.0307      0.069      0.447      0.655      -0.104       0.165\n",
      "==============================================================================\n",
      "Omnibus:                       96.384   Durbin-Watson:                   1.819\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              217.837\n",
      "Skew:                           0.424   Prob(JB):                     4.98e-48\n",
      "Kurtosis:                       4.752   Cond. No.                         291.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OLS; year == 1980\n",
      "===================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              ln_hrwage   R-squared:                       0.169\n",
      "Model:                            OLS   Adj. R-squared:                  0.167\n",
      "Method:                 Least Squares   F-statistic:                     94.08\n",
      "Date:                Sat, 28 Sep 2019   Prob (F-statistic):           6.41e-73\n",
      "Time:                        16:57:50   Log-Likelihood:                -1148.4\n",
      "No. Observations:                1856   AIC:                             2307.\n",
      "Df Residuals:                    1851   BIC:                             2334.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "constant       1.6131      0.075     21.590      0.000       1.467       1.760\n",
      "hyrsed         0.0676      0.004     15.860      0.000       0.059       0.076\n",
      "age            0.0127      0.001     12.281      0.000       0.011       0.015\n",
      "Black         -0.1027      0.044     -2.355      0.019      -0.188      -0.017\n",
      "Others         0.0135      0.071      0.190      0.849      -0.126       0.153\n",
      "==============================================================================\n",
      "Omnibus:                      109.135   Durbin-Watson:                   1.958\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              266.486\n",
      "Skew:                           0.337   Prob(JB):                     1.36e-58\n",
      "Kurtosis:                       4.730   Cond. No.                         302.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OLS; year == 1990\n",
      "===================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              ln_hrwage   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.216\n",
      "Method:                 Least Squares   F-statistic:                     139.3\n",
      "Date:                Sat, 28 Sep 2019   Prob (F-statistic):          3.67e-105\n",
      "Time:                        16:57:50   Log-Likelihood:                -1393.9\n",
      "No. Observations:                2013   AIC:                             2798.\n",
      "Df Residuals:                    2008   BIC:                             2826.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "constant       1.1186      0.084     13.312      0.000       0.954       1.283\n",
      "hyrsed         0.0976      0.005     19.991      0.000       0.088       0.107\n",
      "age            0.0135      0.001     10.785      0.000       0.011       0.016\n",
      "Black         -0.1720      0.048     -3.601      0.000      -0.266      -0.078\n",
      "Others        -0.0597      0.089     -0.670      0.503      -0.234       0.115\n",
      "==============================================================================\n",
      "Omnibus:                      111.834   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              253.156\n",
      "Skew:                           0.342   Prob(JB):                     1.07e-55\n",
      "Kurtosis:                       4.597   Cond. No.                         349.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OLS; year == 2000\n",
      "===================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              ln_hrwage   R-squared:                       0.207\n",
      "Model:                            OLS   Adj. R-squared:                  0.206\n",
      "Method:                 Least Squares   F-statistic:                     168.3\n",
      "Date:                Sat, 28 Sep 2019   Prob (F-statistic):          3.93e-128\n",
      "Time:                        16:57:50   Log-Likelihood:                -2069.0\n",
      "No. Observations:                2580   AIC:                             4148.\n",
      "Df Residuals:                    2575   BIC:                             4177.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "constant       1.1617      0.081     14.419      0.000       1.004       1.320\n",
      "hyrsed         0.1092      0.005     21.168      0.000       0.099       0.119\n",
      "age            0.0110      0.001      9.585      0.000       0.009       0.013\n",
      "Black         -0.2460      0.048     -5.145      0.000      -0.340      -0.152\n",
      "Others        -0.0607      0.060     -1.018      0.309      -0.178       0.056\n",
      "==============================================================================\n",
      "Omnibus:                      305.903   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              708.951\n",
      "Skew:                           0.696   Prob(JB):                    1.13e-154\n",
      "Kurtosis:                       5.158   Cond. No.                         339.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nyears = ['data1971.npy', 'data1980.npy', 'data1990.npy', 'data2000.npy', 'data.npy']\\nfor t in years:\\n    print('OLS for', t)\\n    print('===================')\\n    print(statmod.OLS(endog=t['ln_hrwage'], exog=t[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit().summary())\\n    print('_______________________________________________________________________________________________')\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS \n",
    "\n",
    "#https://lectures.quantecon.org/py/ols.html\n",
    "# to estimate each year separately\n",
    "res_OLS = statmod.OLS(endog=data['ln_hrwage'], exog=data[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit()\n",
    "res71_OLS = statmod.OLS(endog=data1971['ln_hrwage'], exog=data1971[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit()\n",
    "res80_OLS = statmod.OLS(endog=data1980['ln_hrwage'], exog=data1980[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit()\n",
    "res90_OLS = statmod.OLS(endog=data1990['ln_hrwage'], exog=data1990[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit()\n",
    "res2000_OLS = statmod.OLS(endog=data2000['ln_hrwage'], exog=data2000[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit()\n",
    "\n",
    "print('OLS; Full Sample')\n",
    "print('===================')\n",
    "print(res_OLS.summary())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('OLS; year == 1971')\n",
    "print('===================')\n",
    "print(res71_OLS.summary())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('OLS; year == 1980')\n",
    "print('===================')\n",
    "print(res80_OLS.summary())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('OLS; year == 1990')\n",
    "print('===================')\n",
    "print(res90_OLS.summary())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "print('OLS; year == 2000')\n",
    "print('===================')\n",
    "print(res2000_OLS.summary())\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "'''\n",
    "years = ['data1971.npy', 'data1980.npy', 'data1990.npy', 'data2000.npy', 'data.npy']\n",
    "for t in years:\n",
    "    print('OLS for', t)\n",
    "    print('===================')\n",
    "    print(statmod.OLS(endog=t['ln_hrwage'], exog=t[['constant', 'hyrsed', 'age', 'Black', 'Others']]).fit().summary())\n",
    "    print('_______________________________________________________________________________________________')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------\n",
    "# Interpretation (Part 4)\n",
    "# ---------------------------------\n",
    "To answer this question that how the returns to education change over time in these data, we can note that it is increasing. The results for OLS estimation in the full sample indicate that 1 unit increase in the years of education of males will result in a 7.8 % increase in logarithm of their wage. Using data for 1971, we can see that this increase in the wage is as much as 6.7% as a result of each year of increased education for the male heads. We can also see that the percentage of increase in the log of wages is 6.8%, 9.8%, & 11% for 1980, 1990, and 2000, respectively, after one more year of education. \n",
    "\n",
    "In addition, I estimated the same linear model using the maximum likelihood model and the estimated coefficients for the education are 7.8, 6.97, 6.7, 11.8, 10.9 percent for the full sample, 1971 sample of the data, 1980, 1990 and 2000 samples, respectively which supports the estimation of the model using OLS both in magnitude and signature. MLE method can be estimated using several optimization methods for the likelihood function. After using Nelder-Mead method and gaining aforementioned estimations, we used bounded L-BFGS-B and SLSQP methods. The former estimates the coefficients of the education as 7.8, 6.7, 6.7, 9.7, and 10.9 % for the full dataset, 1971, 1980, 1990, 2000 datasets respectively which is againg very close the estimations of the model using OLS methodology. But the latter estimated far away coefficients for the provided samples of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
